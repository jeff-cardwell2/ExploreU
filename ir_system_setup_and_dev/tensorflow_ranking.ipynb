{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "import json\n",
    "import pprint\n",
    "import collections\n",
    "import random\n",
    "random_state = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span Style='font-family: Georgia, serif; color:orange'> **Read/Prepare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels = pd.read_csv('training_qrels_annotated.csv').drop(columns='cip_name')\n",
    "docset = pd.read_csv('final_curriculum_data\\\\final_docset.csv').drop(index=[210, 199, 47, 190]).reset_index(drop=True)\n",
    "cip_titles = pd.read_csv('final_curriculum_data\\\\cip_names.csv')[['Title', 'CIP Code']]\n",
    "cip_titles['CIP Code'] = [i[2:-1] if i[2] != '0' else i[3:-1] for i in cip_titles['CIP Code']]\n",
    "cip_titles['CIP Code'] = [i[:-1] if i[-1] == '0' else i for i in cip_titles['CIP Code']]\n",
    "docset = docset[docset['cip'].isin(cip_titles['CIP Code'])].reset_index(drop=True)\n",
    "docset['cip_name'] = [cip_titles[cip_titles['CIP Code']==i].Title.iloc[0] for i in docset.cip]\n",
    "docset['cip'] = docset['cip'].astype(str)\n",
    "qrels['courses'] = [r['courses'] for i in qrels['cip_code'] for ind, r in docset.iterrows() if str(i) == str(r['cip'])]\n",
    "qrels['descriptions'] = [r['descriptions'] for i in qrels['cip_code'] for ind, r in docset.iterrows() if str(i) == str(r['cip'])]\n",
    "\n",
    "all_queries = pd.read_csv('query_terms.csv')['0'].unique().tolist()\n",
    "all_courses = docset['courses'].astype(str).tolist()\n",
    "all_descriptions = docset['descriptions'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_descriptions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span Style='font-family: Georgia, serif; color:orange'> **Define Helper Functions and Ranking Model**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span Style='font-family: Georgia, serif; color:orange'> **Code Sourced from https://github.com/tensorflow/recommenders/blob/main/tensorflow_recommenders/examples/movielens.py and re-tooled to fit our data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_feature_dict():\n",
    "    return {\"courses\": [], \"descriptions\": [], 'scores':[]}\n",
    "\n",
    "\n",
    "def _sample_list(feature_lists, num_examples_per_list, random_state):\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState()\n",
    "\n",
    "    sampled_indices = random_state.choice(\n",
    "        range(len(feature_lists[\"descriptions\"])),\n",
    "        size=num_examples_per_list,\n",
    "        replace=False,\n",
    "    )\n",
    "    sampled_descriptions = [\n",
    "        feature_lists[\"descriptions\"][idx] for idx in sampled_indices\n",
    "    ]\n",
    "    sampled_courses = [\n",
    "        feature_lists[\"courses\"][idx] for idx in sampled_indices\n",
    "    ]\n",
    "    sampled_scores = [\n",
    "        feature_lists[\"scores\"][idx] for idx in sampled_indices\n",
    "    ]\n",
    "\n",
    "    return (\n",
    "        tf.stack(sampled_courses, 0),\n",
    "        tf.stack(sampled_descriptions, 0),\n",
    "        tf.stack(sampled_scores, 0)\n",
    "    )\n",
    "\n",
    "def sample_listwise(dataset, num_list_per_query, num_examples_per_list, seed):\n",
    "\n",
    "    random_state = np.random.RandomState(seed)\n",
    "\n",
    "    example_lists_by_user = collections.defaultdict(_create_feature_dict)\n",
    "\n",
    "    movie_title_vocab = set()\n",
    "    for example in dataset:\n",
    "        query = example[\"query\"].numpy()\n",
    "        example_lists_by_user[query][\"courses\"].append(\n",
    "            example[\"courses\"])\n",
    "        example_lists_by_user[query][\"descriptions\"].append(\n",
    "            example[\"descriptions\"])\n",
    "        example_lists_by_user[query][\"scores\"].append(\n",
    "            example[\"scores\"])\n",
    "        movie_title_vocab.add(example[\"descriptions\"].numpy())\n",
    "\n",
    "    tensor_slices = {\"query\": [], \"courses\": [], 'descriptions': [], \"scores\": []}\n",
    "\n",
    "    for query, feature_lists in example_lists_by_user.items():\n",
    "        for _ in range(num_list_per_query):\n",
    "\n",
    "            # Drop the user if they don't have enough ratings.\n",
    "            if len(feature_lists[\"scores\"]) < num_examples_per_list:\n",
    "                continue\n",
    "\n",
    "            sampled_courses, sampled_descriptions, sampled_scores = _sample_list(\n",
    "                feature_lists,\n",
    "                num_examples_per_list,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "            tensor_slices[\"query\"].append(query)\n",
    "            tensor_slices[\"courses\"].append(sampled_courses)\n",
    "            tensor_slices[\"descriptions\"].append(sampled_descriptions)\n",
    "            tensor_slices[\"scores\"].append(sampled_scores)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices(tensor_slices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span Style='font-family: Georgia, serif; color:orange'> **Code Sourced from https://www.tensorflow.org/recommenders/examples/listwise_ranking and re-tooled to fit our data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, loss):\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dim = 32\n",
    "\n",
    "        self.query_embeddings = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=all_queries),\n",
    "            tf.keras.layers.Embedding(len(all_queries)+2, embedding_dim)\n",
    "        ])\n",
    "\n",
    "        self.course_embeddings = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=all_courses),\n",
    "            tf.keras.layers.Embedding(len(all_courses)+2, embedding_dim)\n",
    "        ])\n",
    "\n",
    "        self.desc_embeddings = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=all_descriptions),\n",
    "            tf.keras.layers.Embedding(len(all_descriptions)+2, embedding_dim)\n",
    "        ])\n",
    "\n",
    "        self.score_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss=loss,\n",
    "            metrics=[\n",
    "                tfr.keras.metrics.NDCGMetric(topn=10, name='NDCG_top10'),\n",
    "                tf.keras.metrics.RootMeanSquaredError()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        query_embeddings = self.query_embeddings(features['query'])\n",
    "        course_embeddings = self.course_embeddings(features['courses'])\n",
    "        desc_embeddings = self.desc_embeddings(features['descriptions'])\n",
    "        list_length = features[\"descriptions\"].shape[1]\n",
    "        query_embedding_repeated = tf.repeat(\n",
    "            tf.expand_dims(query_embeddings, 1), [list_length], axis=1)\n",
    "\n",
    "        concatenated_embeddings = tf.concat([query_embedding_repeated, course_embeddings, desc_embeddings], 2)\n",
    "\n",
    "        return self.score_model(concatenated_embeddings)\n",
    "\n",
    "    def compute_loss(self, inputs, training = False):\n",
    "        labels = inputs.pop('scores')\n",
    "        scores = self(inputs)\n",
    "\n",
    "        return self.task(\n",
    "            labels=labels,\n",
    "            predictions=tf.squeeze(scores, axis=-1)\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span Style='font-family: Georgia, serif; color:orange'> **Create Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({'query':qrels['query'], 'courses':qrels['courses'], 'descriptions':qrels['descriptions'], 'scores':qrels['assigned_score'].astype(float)})\n",
    "dataset = dataset.shuffle(len(dataset),seed=random_state)\n",
    "training_dataset = dataset.take(round(len(dataset)*.8))\n",
    "test_dataset = dataset.skip(round(len(dataset)*.8))\n",
    "\n",
    "train = sample_listwise(training_dataset, num_list_per_query=20, num_examples_per_list=5, seed=random_state)\n",
    "test = sample_listwise(test_dataset, num_list_per_query=1, num_examples_per_list=5, seed=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(10000).batch(32).cache()\n",
    "cached_test = test.batch(32).cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span Style='font-family: Georgia, serif; color:orange'> **Initialize, Compile, and Train First Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 32\n",
    "\n",
    "listwise = RankingModel(tfr.keras.losses.ListMLELoss())\n",
    "listwise.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2199bfc3130>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listwise.fit(cached_train, epochs=epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG of the ListMLE model: 0.8671\n"
     ]
    }
   ],
   "source": [
    "listwise_model_result = listwise.evaluate(cached_test, return_dict=True, verbose=False)\n",
    "print(\"NDCG of the ListMLE model: {:.4f}\".format(listwise_model_result[\"NDCG_top10\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span Style='font-family: Georgia, serif; color:orange'> **Train Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "166/166 [==============================] - 2s 5ms/step - NDCG_top10: 0.8151 - loss: 4.7873 - regularization_loss: 0.0000e+00 - total_loss: 4.7873\n",
      "Epoch 2/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8220 - loss: 4.7857 - regularization_loss: 0.0000e+00 - total_loss: 4.7857\n",
      "Epoch 3/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8267 - loss: 4.7856 - regularization_loss: 0.0000e+00 - total_loss: 4.7856\n",
      "Epoch 4/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8313 - loss: 4.7846 - regularization_loss: 0.0000e+00 - total_loss: 4.7846\n",
      "Epoch 5/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8335 - loss: 4.7842 - regularization_loss: 0.0000e+00 - total_loss: 4.7842\n",
      "Epoch 6/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8356 - loss: 4.7836 - regularization_loss: 0.0000e+00 - total_loss: 4.7836\n",
      "Epoch 7/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8376 - loss: 4.7830 - regularization_loss: 0.0000e+00 - total_loss: 4.7830\n",
      "Epoch 8/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8401 - loss: 4.7822 - regularization_loss: 0.0000e+00 - total_loss: 4.7822\n",
      "Epoch 9/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8416 - loss: 4.7825 - regularization_loss: 0.0000e+00 - total_loss: 4.7825\n",
      "Epoch 10/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8427 - loss: 4.7813 - regularization_loss: 0.0000e+00 - total_loss: 4.7813\n",
      "Epoch 11/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8438 - loss: 4.7805 - regularization_loss: 0.0000e+00 - total_loss: 4.7805\n",
      "Epoch 12/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8441 - loss: 4.7799 - regularization_loss: 0.0000e+00 - total_loss: 4.7799\n",
      "Epoch 13/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8447 - loss: 4.7799 - regularization_loss: 0.0000e+00 - total_loss: 4.7799\n",
      "Epoch 14/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8458 - loss: 4.7795 - regularization_loss: 0.0000e+00 - total_loss: 4.7795\n",
      "Epoch 15/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8462 - loss: 4.7790 - regularization_loss: 0.0000e+00 - total_loss: 4.7790\n",
      "Epoch 16/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8462 - loss: 4.7786 - regularization_loss: 0.0000e+00 - total_loss: 4.7786\n",
      "Epoch 17/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8464 - loss: 4.7779 - regularization_loss: 0.0000e+00 - total_loss: 4.7779\n",
      "Epoch 18/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8472 - loss: 4.7769 - regularization_loss: 0.0000e+00 - total_loss: 4.7769\n",
      "Epoch 19/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8482 - loss: 4.7767 - regularization_loss: 0.0000e+00 - total_loss: 4.7767\n",
      "Epoch 20/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8495 - loss: 4.7755 - regularization_loss: 0.0000e+00 - total_loss: 4.7755\n",
      "Epoch 21/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8506 - loss: 4.7755 - regularization_loss: 0.0000e+00 - total_loss: 4.7755\n",
      "Epoch 22/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8506 - loss: 4.7746 - regularization_loss: 0.0000e+00 - total_loss: 4.7746\n",
      "Epoch 23/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8508 - loss: 4.7743 - regularization_loss: 0.0000e+00 - total_loss: 4.7743\n",
      "Epoch 24/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8518 - loss: 4.7737 - regularization_loss: 0.0000e+00 - total_loss: 4.7737\n",
      "Epoch 25/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8517 - loss: 4.7739 - regularization_loss: 0.0000e+00 - total_loss: 4.7739\n",
      "Epoch 26/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8519 - loss: 4.7711 - regularization_loss: 0.0000e+00 - total_loss: 4.7711\n",
      "Epoch 27/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8527 - loss: 4.7704 - regularization_loss: 0.0000e+00 - total_loss: 4.7704\n",
      "Epoch 28/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8530 - loss: 4.7712 - regularization_loss: 0.0000e+00 - total_loss: 4.7712\n",
      "Epoch 29/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8532 - loss: 4.7692 - regularization_loss: 0.0000e+00 - total_loss: 4.7692\n",
      "Epoch 30/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8536 - loss: 4.7690 - regularization_loss: 0.0000e+00 - total_loss: 4.7690\n",
      "Epoch 31/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8537 - loss: 4.7673 - regularization_loss: 0.0000e+00 - total_loss: 4.7673\n",
      "Epoch 32/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8542 - loss: 4.7659 - regularization_loss: 0.0000e+00 - total_loss: 4.7659\n",
      "Epoch 33/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8547 - loss: 4.7675 - regularization_loss: 0.0000e+00 - total_loss: 4.7675\n",
      "Epoch 34/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8551 - loss: 4.7641 - regularization_loss: 0.0000e+00 - total_loss: 4.7641\n",
      "Epoch 35/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8552 - loss: 4.7647 - regularization_loss: 0.0000e+00 - total_loss: 4.7647\n",
      "Epoch 36/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8557 - loss: 4.7622 - regularization_loss: 0.0000e+00 - total_loss: 4.7622\n",
      "Epoch 37/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8556 - loss: 4.7621 - regularization_loss: 0.0000e+00 - total_loss: 4.7621\n",
      "Epoch 38/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8560 - loss: 4.7598 - regularization_loss: 0.0000e+00 - total_loss: 4.7598\n",
      "Epoch 39/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8565 - loss: 4.7609 - regularization_loss: 0.0000e+00 - total_loss: 4.7609\n",
      "Epoch 40/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8563 - loss: 4.7598 - regularization_loss: 0.0000e+00 - total_loss: 4.7598\n",
      "Epoch 41/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8563 - loss: 4.7593 - regularization_loss: 0.0000e+00 - total_loss: 4.7593\n",
      "Epoch 42/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8566 - loss: 4.7557 - regularization_loss: 0.0000e+00 - total_loss: 4.7557\n",
      "Epoch 43/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8567 - loss: 4.7565 - regularization_loss: 0.0000e+00 - total_loss: 4.7565\n",
      "Epoch 44/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8565 - loss: 4.7545 - regularization_loss: 0.0000e+00 - total_loss: 4.7545\n",
      "Epoch 45/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8564 - loss: 4.7512 - regularization_loss: 0.0000e+00 - total_loss: 4.7512\n",
      "Epoch 46/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8563 - loss: 4.7513 - regularization_loss: 0.0000e+00 - total_loss: 4.7513\n",
      "Epoch 47/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8566 - loss: 4.7509 - regularization_loss: 0.0000e+00 - total_loss: 4.7509\n",
      "Epoch 48/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8568 - loss: 4.7472 - regularization_loss: 0.0000e+00 - total_loss: 4.7472\n",
      "Epoch 49/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8566 - loss: 4.7495 - regularization_loss: 0.0000e+00 - total_loss: 4.7495\n",
      "Epoch 50/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8568 - loss: 4.7485 - regularization_loss: 0.0000e+00 - total_loss: 4.7485\n",
      "Epoch 51/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8570 - loss: 4.7457 - regularization_loss: 0.0000e+00 - total_loss: 4.7457\n",
      "Epoch 52/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8567 - loss: 4.7425 - regularization_loss: 0.0000e+00 - total_loss: 4.7425\n",
      "Epoch 53/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8561 - loss: 4.7400 - regularization_loss: 0.0000e+00 - total_loss: 4.7400\n",
      "Epoch 54/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8568 - loss: 4.7445 - regularization_loss: 0.0000e+00 - total_loss: 4.7445\n",
      "Epoch 55/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8567 - loss: 4.7449 - regularization_loss: 0.0000e+00 - total_loss: 4.7449\n",
      "Epoch 56/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8568 - loss: 4.7407 - regularization_loss: 0.0000e+00 - total_loss: 4.7407\n",
      "Epoch 57/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8566 - loss: 4.7386 - regularization_loss: 0.0000e+00 - total_loss: 4.7386\n",
      "Epoch 58/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8566 - loss: 4.7384 - regularization_loss: 0.0000e+00 - total_loss: 4.7384\n",
      "Epoch 59/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8569 - loss: 4.7337 - regularization_loss: 0.0000e+00 - total_loss: 4.7337\n",
      "Epoch 60/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8567 - loss: 4.7364 - regularization_loss: 0.0000e+00 - total_loss: 4.7364\n",
      "Epoch 61/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8573 - loss: 4.7383 - regularization_loss: 0.0000e+00 - total_loss: 4.7383\n",
      "Epoch 62/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8573 - loss: 4.7385 - regularization_loss: 0.0000e+00 - total_loss: 4.7385\n",
      "Epoch 63/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8575 - loss: 4.7358 - regularization_loss: 0.0000e+00 - total_loss: 4.7358\n",
      "Epoch 64/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8577 - loss: 4.7303 - regularization_loss: 0.0000e+00 - total_loss: 4.7303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x219faef3040>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = sample_listwise(training_dataset, num_list_per_query=30, num_examples_per_list=5, seed=random_state)\n",
    "test = sample_listwise(test_dataset, num_list_per_query=1, num_examples_per_list=5, seed=random_state)\n",
    "cached_train = train.shuffle(10000, seed=random_state).batch(32).cache()\n",
    "cached_test = test.batch(32).cache()\n",
    "epochs = 64\n",
    "listwise = RankingModel(tfr.keras.losses.ListMLELoss())\n",
    "listwise.compile(optimizer=tf.keras.optimizers.Adagrad(0.001))\n",
    "listwise.fit(cached_train, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - NDCG_top10: 0.8654 - loss: 4.7332 - regularization_loss: 0.0000e+00 - total_loss: 4.7332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8653592467308044"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listwise_model_result = listwise.evaluate(cached_test, return_dict=True)\n",
    "listwise_model_result['NDCG_top10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8284 - loss: 0.8890 - regularization_loss: 0.0000e+00 - total_loss: 0.8890\n",
      "Epoch 2/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8427 - loss: 0.8819 - regularization_loss: 0.0000e+00 - total_loss: 0.8819\n",
      "Epoch 3/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8495 - loss: 0.8682 - regularization_loss: 0.0000e+00 - total_loss: 0.8682\n",
      "Epoch 4/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8528 - loss: 0.8260 - regularization_loss: 0.0000e+00 - total_loss: 0.8260\n",
      "Epoch 5/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8570 - loss: 0.7237 - regularization_loss: 0.0000e+00 - total_loss: 0.7237\n",
      "Epoch 6/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8628 - loss: 0.6879 - regularization_loss: 0.0000e+00 - total_loss: 0.6879\n",
      "Epoch 7/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8643 - loss: 0.6798 - regularization_loss: 0.0000e+00 - total_loss: 0.6798\n",
      "Epoch 8/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8643 - loss: 0.6764 - regularization_loss: 0.0000e+00 - total_loss: 0.6764\n",
      "Epoch 9/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8650 - loss: 0.6748 - regularization_loss: 0.0000e+00 - total_loss: 0.6748\n",
      "Epoch 10/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8651 - loss: 0.6737 - regularization_loss: 0.0000e+00 - total_loss: 0.6737\n",
      "Epoch 11/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8650 - loss: 0.6729 - regularization_loss: 0.0000e+00 - total_loss: 0.6729\n",
      "Epoch 12/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8651 - loss: 0.6723 - regularization_loss: 0.0000e+00 - total_loss: 0.6723\n",
      "Epoch 13/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6718 - regularization_loss: 0.0000e+00 - total_loss: 0.6718\n",
      "Epoch 14/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8651 - loss: 0.6714 - regularization_loss: 0.0000e+00 - total_loss: 0.6714\n",
      "Epoch 15/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6711 - regularization_loss: 0.0000e+00 - total_loss: 0.6711\n",
      "Epoch 16/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6708 - regularization_loss: 0.0000e+00 - total_loss: 0.6708\n",
      "Epoch 17/64\n",
      "166/166 [==============================] - 1s 3ms/step - NDCG_top10: 0.8652 - loss: 0.6705 - regularization_loss: 0.0000e+00 - total_loss: 0.6705\n",
      "Epoch 18/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6703 - regularization_loss: 0.0000e+00 - total_loss: 0.6703\n",
      "Epoch 19/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8651 - loss: 0.6701 - regularization_loss: 0.0000e+00 - total_loss: 0.6701\n",
      "Epoch 20/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6699 - regularization_loss: 0.0000e+00 - total_loss: 0.6699\n",
      "Epoch 21/64\n",
      "166/166 [==============================] - 1s 3ms/step - NDCG_top10: 0.8651 - loss: 0.6697 - regularization_loss: 0.0000e+00 - total_loss: 0.6697\n",
      "Epoch 22/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6696 - regularization_loss: 0.0000e+00 - total_loss: 0.6696\n",
      "Epoch 23/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8649 - loss: 0.6694 - regularization_loss: 0.0000e+00 - total_loss: 0.6694\n",
      "Epoch 24/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6693 - regularization_loss: 0.0000e+00 - total_loss: 0.6693\n",
      "Epoch 25/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6691 - regularization_loss: 0.0000e+00 - total_loss: 0.6691\n",
      "Epoch 26/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8651 - loss: 0.6690 - regularization_loss: 0.0000e+00 - total_loss: 0.6690\n",
      "Epoch 27/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6689 - regularization_loss: 0.0000e+00 - total_loss: 0.6689\n",
      "Epoch 28/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6688 - regularization_loss: 0.0000e+00 - total_loss: 0.6688\n",
      "Epoch 29/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8655 - loss: 0.6687 - regularization_loss: 0.0000e+00 - total_loss: 0.6687\n",
      "Epoch 30/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6686 - regularization_loss: 0.0000e+00 - total_loss: 0.6686\n",
      "Epoch 31/64\n",
      "166/166 [==============================] - 1s 3ms/step - NDCG_top10: 0.8652 - loss: 0.6685 - regularization_loss: 0.0000e+00 - total_loss: 0.6685\n",
      "Epoch 32/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6684 - regularization_loss: 0.0000e+00 - total_loss: 0.6684\n",
      "Epoch 33/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6683 - regularization_loss: 0.0000e+00 - total_loss: 0.6683\n",
      "Epoch 34/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6682 - regularization_loss: 0.0000e+00 - total_loss: 0.6682\n",
      "Epoch 35/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6681 - regularization_loss: 0.0000e+00 - total_loss: 0.6681\n",
      "Epoch 36/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6681 - regularization_loss: 0.0000e+00 - total_loss: 0.6681\n",
      "Epoch 37/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6680 - regularization_loss: 0.0000e+00 - total_loss: 0.6680\n",
      "Epoch 38/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6679 - regularization_loss: 0.0000e+00 - total_loss: 0.6679\n",
      "Epoch 39/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6679 - regularization_loss: 0.0000e+00 - total_loss: 0.6679\n",
      "Epoch 40/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6678 - regularization_loss: 0.0000e+00 - total_loss: 0.6678\n",
      "Epoch 41/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8651 - loss: 0.6678 - regularization_loss: 0.0000e+00 - total_loss: 0.6678\n",
      "Epoch 42/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8651 - loss: 0.6677 - regularization_loss: 0.0000e+00 - total_loss: 0.6677\n",
      "Epoch 43/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6676 - regularization_loss: 0.0000e+00 - total_loss: 0.6676\n",
      "Epoch 44/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6676 - regularization_loss: 0.0000e+00 - total_loss: 0.6676\n",
      "Epoch 45/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6675 - regularization_loss: 0.0000e+00 - total_loss: 0.6675\n",
      "Epoch 46/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8650 - loss: 0.6675 - regularization_loss: 0.0000e+00 - total_loss: 0.6675\n",
      "Epoch 47/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6674 - regularization_loss: 0.0000e+00 - total_loss: 0.6674\n",
      "Epoch 48/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8651 - loss: 0.6674 - regularization_loss: 0.0000e+00 - total_loss: 0.6674\n",
      "Epoch 49/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8656 - loss: 0.6674 - regularization_loss: 0.0000e+00 - total_loss: 0.6674\n",
      "Epoch 50/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6673 - regularization_loss: 0.0000e+00 - total_loss: 0.6673\n",
      "Epoch 51/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8651 - loss: 0.6673 - regularization_loss: 0.0000e+00 - total_loss: 0.6673\n",
      "Epoch 52/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6672 - regularization_loss: 0.0000e+00 - total_loss: 0.6672\n",
      "Epoch 53/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8651 - loss: 0.6672 - regularization_loss: 0.0000e+00 - total_loss: 0.6672\n",
      "Epoch 54/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6671 - regularization_loss: 0.0000e+00 - total_loss: 0.6671\n",
      "Epoch 55/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6671 - regularization_loss: 0.0000e+00 - total_loss: 0.6671\n",
      "Epoch 56/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6671 - regularization_loss: 0.0000e+00 - total_loss: 0.6671\n",
      "Epoch 57/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6670 - regularization_loss: 0.0000e+00 - total_loss: 0.6670\n",
      "Epoch 58/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8652 - loss: 0.6670 - regularization_loss: 0.0000e+00 - total_loss: 0.6670\n",
      "Epoch 59/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8651 - loss: 0.6670 - regularization_loss: 0.0000e+00 - total_loss: 0.6670\n",
      "Epoch 60/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6669 - regularization_loss: 0.0000e+00 - total_loss: 0.6669\n",
      "Epoch 61/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6669 - regularization_loss: 0.0000e+00 - total_loss: 0.6669\n",
      "Epoch 62/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8654 - loss: 0.6669 - regularization_loss: 0.0000e+00 - total_loss: 0.6669\n",
      "Epoch 63/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6668 - regularization_loss: 0.0000e+00 - total_loss: 0.6668\n",
      "Epoch 64/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8653 - loss: 0.6668 - regularization_loss: 0.0000e+00 - total_loss: 0.6668\n",
      "4/4 [==============================] - 0s 4ms/step - NDCG_top10: 0.8639 - loss: 0.6763 - regularization_loss: 0.0000e+00 - total_loss: 0.6763\n",
      "NDCG of the pairwise hinge loss model: 0.8639\n"
     ]
    }
   ],
   "source": [
    "hinge_model = RankingModel(tfr.keras.losses.PairwiseHingeLoss())\n",
    "hinge_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01))\n",
    "hinge_model.fit(cached_train, epochs=epochs, verbose=1)\n",
    "hinge_model_result = hinge_model.evaluate(cached_test, return_dict=True)\n",
    "print(\"NDCG of the pairwise hinge loss model: {:.4f}\".format(hinge_model_result[\"NDCG_top10\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8409 - root_mean_squared_error: 1.1563 - loss: 1.3373 - regularization_loss: 0.0000e+00 - total_loss: 1.3373\n",
      "Epoch 2/64\n",
      "166/166 [==============================] - 1s 3ms/step - NDCG_top10: 0.8538 - root_mean_squared_error: 1.1184 - loss: 1.2515 - regularization_loss: 0.0000e+00 - total_loss: 1.2515\n",
      "Epoch 3/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8547 - root_mean_squared_error: 1.1150 - loss: 1.2440 - regularization_loss: 0.0000e+00 - total_loss: 1.2440\n",
      "Epoch 4/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8552 - root_mean_squared_error: 1.1135 - loss: 1.2407 - regularization_loss: 0.0000e+00 - total_loss: 1.2407\n",
      "Epoch 5/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8554 - root_mean_squared_error: 1.1126 - loss: 1.2387 - regularization_loss: 0.0000e+00 - total_loss: 1.2387\n",
      "Epoch 6/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8556 - root_mean_squared_error: 1.1120 - loss: 1.2373 - regularization_loss: 0.0000e+00 - total_loss: 1.2373\n",
      "Epoch 7/64\n",
      "166/166 [==============================] - 1s 3ms/step - NDCG_top10: 0.8556 - root_mean_squared_error: 1.1115 - loss: 1.2362 - regularization_loss: 0.0000e+00 - total_loss: 1.2362\n",
      "Epoch 8/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8560 - root_mean_squared_error: 1.1112 - loss: 1.2354 - regularization_loss: 0.0000e+00 - total_loss: 1.2354\n",
      "Epoch 9/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8561 - root_mean_squared_error: 1.1108 - loss: 1.2347 - regularization_loss: 0.0000e+00 - total_loss: 1.2347\n",
      "Epoch 10/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8560 - root_mean_squared_error: 1.1106 - loss: 1.2341 - regularization_loss: 0.0000e+00 - total_loss: 1.2341\n",
      "Epoch 11/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8561 - root_mean_squared_error: 1.1103 - loss: 1.2336 - regularization_loss: 0.0000e+00 - total_loss: 1.2336\n",
      "Epoch 12/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8563 - root_mean_squared_error: 1.1101 - loss: 1.2331 - regularization_loss: 0.0000e+00 - total_loss: 1.2331\n",
      "Epoch 13/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8564 - root_mean_squared_error: 1.1100 - loss: 1.2328 - regularization_loss: 0.0000e+00 - total_loss: 1.2328\n",
      "Epoch 14/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8564 - root_mean_squared_error: 1.1098 - loss: 1.2324 - regularization_loss: 0.0000e+00 - total_loss: 1.2324\n",
      "Epoch 15/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8566 - root_mean_squared_error: 1.1097 - loss: 1.2321 - regularization_loss: 0.0000e+00 - total_loss: 1.2321\n",
      "Epoch 16/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8565 - root_mean_squared_error: 1.1095 - loss: 1.2318 - regularization_loss: 0.0000e+00 - total_loss: 1.2318\n",
      "Epoch 17/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8563 - root_mean_squared_error: 1.1094 - loss: 1.2315 - regularization_loss: 0.0000e+00 - total_loss: 1.2315\n",
      "Epoch 18/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8565 - root_mean_squared_error: 1.1093 - loss: 1.2313 - regularization_loss: 0.0000e+00 - total_loss: 1.2313\n",
      "Epoch 19/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8564 - root_mean_squared_error: 1.1092 - loss: 1.2311 - regularization_loss: 0.0000e+00 - total_loss: 1.2311\n",
      "Epoch 20/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8565 - root_mean_squared_error: 1.1091 - loss: 1.2309 - regularization_loss: 0.0000e+00 - total_loss: 1.2309\n",
      "Epoch 21/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8565 - root_mean_squared_error: 1.1090 - loss: 1.2307 - regularization_loss: 0.0000e+00 - total_loss: 1.2307\n",
      "Epoch 22/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8565 - root_mean_squared_error: 1.1090 - loss: 1.2305 - regularization_loss: 0.0000e+00 - total_loss: 1.2305\n",
      "Epoch 23/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8566 - root_mean_squared_error: 1.1089 - loss: 1.2304 - regularization_loss: 0.0000e+00 - total_loss: 1.2304\n",
      "Epoch 24/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8565 - root_mean_squared_error: 1.1088 - loss: 1.2302 - regularization_loss: 0.0000e+00 - total_loss: 1.2302\n",
      "Epoch 25/64\n",
      "166/166 [==============================] - 1s 3ms/step - NDCG_top10: 0.8563 - root_mean_squared_error: 1.1088 - loss: 1.2301 - regularization_loss: 0.0000e+00 - total_loss: 1.2301\n",
      "Epoch 26/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8563 - root_mean_squared_error: 1.1087 - loss: 1.2299 - regularization_loss: 0.0000e+00 - total_loss: 1.2299\n",
      "Epoch 27/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8563 - root_mean_squared_error: 1.1086 - loss: 1.2298 - regularization_loss: 0.0000e+00 - total_loss: 1.2298\n",
      "Epoch 28/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8563 - root_mean_squared_error: 1.1086 - loss: 1.2297 - regularization_loss: 0.0000e+00 - total_loss: 1.2297\n",
      "Epoch 29/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8564 - root_mean_squared_error: 1.1085 - loss: 1.2296 - regularization_loss: 0.0000e+00 - total_loss: 1.2296\n",
      "Epoch 30/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8565 - root_mean_squared_error: 1.1085 - loss: 1.2295 - regularization_loss: 0.0000e+00 - total_loss: 1.2295\n",
      "Epoch 31/64\n",
      "166/166 [==============================] - 1s 3ms/step - NDCG_top10: 0.8564 - root_mean_squared_error: 1.1084 - loss: 1.2294 - regularization_loss: 0.0000e+00 - total_loss: 1.2294\n",
      "Epoch 32/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8563 - root_mean_squared_error: 1.1084 - loss: 1.2293 - regularization_loss: 0.0000e+00 - total_loss: 1.2293\n",
      "Epoch 33/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8565 - root_mean_squared_error: 1.1084 - loss: 1.2292 - regularization_loss: 0.0000e+00 - total_loss: 1.2292\n",
      "Epoch 34/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8565 - root_mean_squared_error: 1.1083 - loss: 1.2291 - regularization_loss: 0.0000e+00 - total_loss: 1.2291\n",
      "Epoch 35/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8566 - root_mean_squared_error: 1.1083 - loss: 1.2290 - regularization_loss: 0.0000e+00 - total_loss: 1.2290\n",
      "Epoch 36/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8567 - root_mean_squared_error: 1.1082 - loss: 1.2289 - regularization_loss: 0.0000e+00 - total_loss: 1.2289\n",
      "Epoch 37/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8566 - root_mean_squared_error: 1.1082 - loss: 1.2288 - regularization_loss: 0.0000e+00 - total_loss: 1.2288\n",
      "Epoch 38/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8567 - root_mean_squared_error: 1.1082 - loss: 1.2288 - regularization_loss: 0.0000e+00 - total_loss: 1.2288\n",
      "Epoch 39/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8567 - root_mean_squared_error: 1.1081 - loss: 1.2287 - regularization_loss: 0.0000e+00 - total_loss: 1.2287\n",
      "Epoch 40/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8567 - root_mean_squared_error: 1.1081 - loss: 1.2286 - regularization_loss: 0.0000e+00 - total_loss: 1.2286\n",
      "Epoch 41/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8566 - root_mean_squared_error: 1.1081 - loss: 1.2286 - regularization_loss: 0.0000e+00 - total_loss: 1.2286\n",
      "Epoch 42/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8567 - root_mean_squared_error: 1.1080 - loss: 1.2285 - regularization_loss: 0.0000e+00 - total_loss: 1.2285\n",
      "Epoch 43/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8568 - root_mean_squared_error: 1.1080 - loss: 1.2284 - regularization_loss: 0.0000e+00 - total_loss: 1.2284\n",
      "Epoch 44/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8569 - root_mean_squared_error: 1.1080 - loss: 1.2284 - regularization_loss: 0.0000e+00 - total_loss: 1.2284\n",
      "Epoch 45/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1080 - loss: 1.2283 - regularization_loss: 0.0000e+00 - total_loss: 1.2283\n",
      "Epoch 46/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1079 - loss: 1.2283 - regularization_loss: 0.0000e+00 - total_loss: 1.2283\n",
      "Epoch 47/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1079 - loss: 1.2282 - regularization_loss: 0.0000e+00 - total_loss: 1.2282\n",
      "Epoch 48/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1079 - loss: 1.2281 - regularization_loss: 0.0000e+00 - total_loss: 1.2281\n",
      "Epoch 49/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1079 - loss: 1.2281 - regularization_loss: 0.0000e+00 - total_loss: 1.2281\n",
      "Epoch 50/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1078 - loss: 1.2280 - regularization_loss: 0.0000e+00 - total_loss: 1.2280\n",
      "Epoch 51/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1078 - loss: 1.2280 - regularization_loss: 0.0000e+00 - total_loss: 1.2280\n",
      "Epoch 52/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1078 - loss: 1.2279 - regularization_loss: 0.0000e+00 - total_loss: 1.2279\n",
      "Epoch 53/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1078 - loss: 1.2279 - regularization_loss: 0.0000e+00 - total_loss: 1.2279\n",
      "Epoch 54/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1077 - loss: 1.2278 - regularization_loss: 0.0000e+00 - total_loss: 1.2278\n",
      "Epoch 55/64\n",
      "166/166 [==============================] - 1s 3ms/step - NDCG_top10: 0.8572 - root_mean_squared_error: 1.1077 - loss: 1.2278 - regularization_loss: 0.0000e+00 - total_loss: 1.2278\n",
      "Epoch 56/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8572 - root_mean_squared_error: 1.1077 - loss: 1.2277 - regularization_loss: 0.0000e+00 - total_loss: 1.2277\n",
      "Epoch 57/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8572 - root_mean_squared_error: 1.1077 - loss: 1.2277 - regularization_loss: 0.0000e+00 - total_loss: 1.2277\n",
      "Epoch 58/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8572 - root_mean_squared_error: 1.1077 - loss: 1.2277 - regularization_loss: 0.0000e+00 - total_loss: 1.2277\n",
      "Epoch 59/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8572 - root_mean_squared_error: 1.1076 - loss: 1.2276 - regularization_loss: 0.0000e+00 - total_loss: 1.2276\n",
      "Epoch 60/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1076 - loss: 1.2276 - regularization_loss: 0.0000e+00 - total_loss: 1.2276\n",
      "Epoch 61/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1076 - loss: 1.2275 - regularization_loss: 0.0000e+00 - total_loss: 1.2275\n",
      "Epoch 62/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8571 - root_mean_squared_error: 1.1076 - loss: 1.2275 - regularization_loss: 0.0000e+00 - total_loss: 1.2275\n",
      "Epoch 63/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8572 - root_mean_squared_error: 1.1076 - loss: 1.2274 - regularization_loss: 0.0000e+00 - total_loss: 1.2274\n",
      "Epoch 64/64\n",
      "166/166 [==============================] - 1s 4ms/step - NDCG_top10: 0.8570 - root_mean_squared_error: 1.1076 - loss: 1.2274 - regularization_loss: 0.0000e+00 - total_loss: 1.2274\n",
      "4/4 [==============================] - 0s 4ms/step - NDCG_top10: 0.8705 - root_mean_squared_error: 1.0243 - loss: 1.1377 - regularization_loss: 0.0000e+00 - total_loss: 1.1377\n",
      "NDCG of the MSE Model: 0.8705\n"
     ]
    }
   ],
   "source": [
    "mse_model = RankingModel(tf.keras.losses.MeanSquaredError())\n",
    "mse_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "mse_model.fit(cached_train, epochs=epochs, verbose=1)\n",
    "mse_model_result = mse_model.evaluate(cached_test, return_dict=True)\n",
    "print(\"NDCG of the MSE Model: {:.4f}\".format(mse_model_result[\"NDCG_top10\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span Style='font-family: Georgia, serif; color:orange'> **Define Prediction Generation and Test Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(query, model):\n",
    "    prediction_dataset = tf.data.Dataset.from_tensor_slices({'query':[[query]],'courses':[[all_courses]], 'descriptions':[[all_descriptions]]})\n",
    "    prediction_input = list(prediction_dataset.as_numpy_iterator())[0]\n",
    "\n",
    "    query_embeddings = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=all_queries),\n",
    "            tf.keras.layers.Embedding(len(all_queries)+2, 32)\n",
    "        ])\n",
    "    q_embed = query_embeddings(prediction_input['query'])\n",
    "\n",
    "    course_embeddings = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=all_courses),\n",
    "            tf.keras.layers.Embedding(len(all_courses)+2, 32)\n",
    "        ])\n",
    "    c_embed = course_embeddings(prediction_input['courses'])\n",
    "\n",
    "    description_embeddings = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=all_descriptions),\n",
    "            tf.keras.layers.Embedding(len(all_descriptions)+2, 32)\n",
    "        ])\n",
    "    d_embed = description_embeddings(prediction_input['descriptions'])\n",
    "\n",
    "    query_embedding_repeated = tf.repeat(tf.expand_dims(q_embed, 1), 192, axis=1)\n",
    "\n",
    "    concatenated_embeddings = tf.concat([query_embedding_repeated, c_embed, d_embed], 2)\n",
    "\n",
    "    concatenated_embeddings\n",
    "\n",
    "    preds = model.score_model(concatenated_embeddings)\n",
    "    scores = pd.DataFrame({'score':tf.squeeze(preds,-1).numpy()[0]})\n",
    "    top_scores = scores.sort_values('score', ascending=False).head(20)\n",
    "    top_scores['query'] = [query]*20\n",
    "    top_scores['cip'] = [docset.iloc[i]['cip'] for i in top_scores.index]\n",
    "    top_scores['cip_name'] = [docset.iloc[i]['cip_name'] for i in top_scores.index]\n",
    "\n",
    "    return top_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "      <th>cip</th>\n",
       "      <th>cip_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.068278</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>14.08</td>\n",
       "      <td>Civil Engineering.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.058790</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>50.06</td>\n",
       "      <td>Film/Video and Photographic Arts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.032189</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>27.05</td>\n",
       "      <td>Statistics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.022193</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>16.04</td>\n",
       "      <td>Slavic, Baltic and Albanian Languages, Literat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.020108</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>52.07</td>\n",
       "      <td>Entrepreneurial and Small Business Operations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.018535</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>1.09</td>\n",
       "      <td>Animal Sciences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.017036</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>52.15</td>\n",
       "      <td>Real Estate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.017001</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>14.42</td>\n",
       "      <td>Mechatronics, Robotics, and Automation Enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.012546</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>26.09</td>\n",
       "      <td>Physiology, Pathology and Related Sciences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.010752</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>30.01</td>\n",
       "      <td>Biological and Physical Sciences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010464</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>5.02</td>\n",
       "      <td>Ethnic, Cultural Minority, Gender, and Group S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.008908</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>50.04</td>\n",
       "      <td>Design and Applied Arts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.008193</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>26.15</td>\n",
       "      <td>Neurobiology and Neurosciences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.005760</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>52.16</td>\n",
       "      <td>Taxation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.003328</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>51.15</td>\n",
       "      <td>Mental and Social Health Services and Allied P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.000517</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>52.02</td>\n",
       "      <td>Business Administration, Management and Operat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.003310</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>11.99</td>\n",
       "      <td>Computer and Information Sciences and Support ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.003384</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>42.28</td>\n",
       "      <td>Clinical, Counseling and Applied Psychology.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.006745</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>52.1</td>\n",
       "      <td>Human Resources Management and Services.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-0.008397</td>\n",
       "      <td>Science Writing</td>\n",
       "      <td>30.14</td>\n",
       "      <td>Museology/Museum Studies.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score            query    cip  \\\n",
       "31   0.068278  Science Writing  14.08   \n",
       "46   0.058790  Science Writing  50.06   \n",
       "107  0.032189  Science Writing  27.05   \n",
       "27   0.022193  Science Writing  16.04   \n",
       "149  0.020108  Science Writing  52.07   \n",
       "78   0.018535  Science Writing   1.09   \n",
       "180  0.017036  Science Writing  52.15   \n",
       "108  0.017001  Science Writing  14.42   \n",
       "137  0.012546  Science Writing  26.09   \n",
       "138  0.010752  Science Writing  30.01   \n",
       "0    0.010464  Science Writing   5.02   \n",
       "43   0.008908  Science Writing  50.04   \n",
       "20   0.008193  Science Writing  26.15   \n",
       "188  0.005760  Science Writing  52.16   \n",
       "157  0.003328  Science Writing  51.15   \n",
       "51  -0.000517  Science Writing  52.02   \n",
       "160 -0.003310  Science Writing  11.99   \n",
       "156 -0.003384  Science Writing  42.28   \n",
       "64  -0.006745  Science Writing   52.1   \n",
       "179 -0.008397  Science Writing  30.14   \n",
       "\n",
       "                                              cip_name  \n",
       "31                                  Civil Engineering.  \n",
       "46                   Film/Video and Photographic Arts.  \n",
       "107                                        Statistics.  \n",
       "27   Slavic, Baltic and Albanian Languages, Literat...  \n",
       "149     Entrepreneurial and Small Business Operations.  \n",
       "78                                    Animal Sciences.  \n",
       "180                                       Real Estate.  \n",
       "108  Mechatronics, Robotics, and Automation Enginee...  \n",
       "137        Physiology, Pathology and Related Sciences.  \n",
       "138                  Biological and Physical Sciences.  \n",
       "0    Ethnic, Cultural Minority, Gender, and Group S...  \n",
       "43                            Design and Applied Arts.  \n",
       "20                     Neurobiology and Neurosciences.  \n",
       "188                                          Taxation.  \n",
       "157  Mental and Social Health Services and Allied P...  \n",
       "51   Business Administration, Management and Operat...  \n",
       "160  Computer and Information Sciences and Support ...  \n",
       "156       Clinical, Counseling and Applied Psychology.  \n",
       "64            Human Resources Management and Services.  \n",
       "179                          Museology/Museum Studies.  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = random.choice(all_queries)\n",
    "generate_predictions(query, listwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "      <th>cip</th>\n",
       "      <th>cip_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.278183</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>11.09</td>\n",
       "      <td>Computer Systems Networking and Telecommunicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.242642</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>26.02</td>\n",
       "      <td>Biochemistry, Biophysics and Molecular Biology.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.234664</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>26.12</td>\n",
       "      <td>Biotechnology.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.195087</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>27.01</td>\n",
       "      <td>Mathematics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.152327</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>30.1</td>\n",
       "      <td>Biopsychology.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.140576</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>42.28</td>\n",
       "      <td>Clinical, Counseling and Applied Psychology.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.134695</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>51.38</td>\n",
       "      <td>Registered Nursing, Nursing Administration, Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.129398</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>1.09</td>\n",
       "      <td>Animal Sciences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.128367</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>50.05</td>\n",
       "      <td>Drama/Theatre Arts and Stagecraft.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.125817</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>14.02</td>\n",
       "      <td>Aerospace, Aeronautical, and Astronautical/Spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.118875</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>14.08</td>\n",
       "      <td>Civil Engineering.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.118848</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>49.01</td>\n",
       "      <td>Air Transportation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.113625</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>26.11</td>\n",
       "      <td>Biomathematics, Bioinformatics, and Computatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.113235</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>22.02</td>\n",
       "      <td>Legal Research and Advanced Professional Studies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.107193</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>52.12</td>\n",
       "      <td>Management Information Systems and Services.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.106676</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>51.23</td>\n",
       "      <td>Rehabilitation and Therapeutic Professions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.096351</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>19.06</td>\n",
       "      <td>Housing and Human Environments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080577</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>40.02</td>\n",
       "      <td>Astronomy and Astrophysics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.064293</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>26.99</td>\n",
       "      <td>Biological and Biomedical Sciences, Other.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.062084</td>\n",
       "      <td>Kinesiology</td>\n",
       "      <td>14.18</td>\n",
       "      <td>Materials Engineering.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score        query    cip  \\\n",
       "110  0.278183  Kinesiology  11.09   \n",
       "18   0.242642  Kinesiology  26.02   \n",
       "37   0.234664  Kinesiology  26.12   \n",
       "17   0.195087  Kinesiology  27.01   \n",
       "167  0.152327  Kinesiology   30.1   \n",
       "156  0.140576  Kinesiology  42.28   \n",
       "58   0.134695  Kinesiology  51.38   \n",
       "78   0.129398  Kinesiology   1.09   \n",
       "71   0.128367  Kinesiology  50.05   \n",
       "33   0.125817  Kinesiology  14.02   \n",
       "31   0.118875  Kinesiology  14.08   \n",
       "74   0.118848  Kinesiology  49.01   \n",
       "159  0.113625  Kinesiology  26.11   \n",
       "38   0.113235  Kinesiology  22.02   \n",
       "181  0.107193  Kinesiology  52.12   \n",
       "112  0.106676  Kinesiology  51.23   \n",
       "92   0.096351  Kinesiology  19.06   \n",
       "4    0.080577  Kinesiology  40.02   \n",
       "185  0.064293  Kinesiology  26.99   \n",
       "128  0.062084  Kinesiology  14.18   \n",
       "\n",
       "                                              cip_name  \n",
       "110  Computer Systems Networking and Telecommunicat...  \n",
       "18     Biochemistry, Biophysics and Molecular Biology.  \n",
       "37                                      Biotechnology.  \n",
       "17                                        Mathematics.  \n",
       "167                                     Biopsychology.  \n",
       "156       Clinical, Counseling and Applied Psychology.  \n",
       "58   Registered Nursing, Nursing Administration, Nu...  \n",
       "78                                    Animal Sciences.  \n",
       "71                  Drama/Theatre Arts and Stagecraft.  \n",
       "33   Aerospace, Aeronautical, and Astronautical/Spa...  \n",
       "31                                  Civil Engineering.  \n",
       "74                                 Air Transportation.  \n",
       "159  Biomathematics, Bioinformatics, and Computatio...  \n",
       "38   Legal Research and Advanced Professional Studies.  \n",
       "181       Management Information Systems and Services.  \n",
       "112        Rehabilitation and Therapeutic Professions.  \n",
       "92                     Housing and Human Environments.  \n",
       "4                          Astronomy and Astrophysics.  \n",
       "185         Biological and Biomedical Sciences, Other.  \n",
       "128                             Materials Engineering.  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = random.choice(all_queries)\n",
    "generate_predictions(query, hinge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "      <th>cip</th>\n",
       "      <th>cip_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.780989</td>\n",
       "      <td>Debate</td>\n",
       "      <td>50.07</td>\n",
       "      <td>Fine and Studio Arts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.778566</td>\n",
       "      <td>Debate</td>\n",
       "      <td>38.01</td>\n",
       "      <td>Philosophy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.763501</td>\n",
       "      <td>Debate</td>\n",
       "      <td>14.18</td>\n",
       "      <td>Materials Engineering.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.759955</td>\n",
       "      <td>Debate</td>\n",
       "      <td>45.1</td>\n",
       "      <td>Political Science and Government.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.754979</td>\n",
       "      <td>Debate</td>\n",
       "      <td>52.16</td>\n",
       "      <td>Taxation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.748719</td>\n",
       "      <td>Debate</td>\n",
       "      <td>19.06</td>\n",
       "      <td>Housing and Human Environments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.745737</td>\n",
       "      <td>Debate</td>\n",
       "      <td>45.06</td>\n",
       "      <td>Economics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.745663</td>\n",
       "      <td>Debate</td>\n",
       "      <td>14.08</td>\n",
       "      <td>Civil Engineering.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.742177</td>\n",
       "      <td>Debate</td>\n",
       "      <td>52.07</td>\n",
       "      <td>Entrepreneurial and Small Business Operations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.741174</td>\n",
       "      <td>Debate</td>\n",
       "      <td>31.05</td>\n",
       "      <td>Sports, Kinesiology, and Physical Education/Fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.740697</td>\n",
       "      <td>Debate</td>\n",
       "      <td>43.01</td>\n",
       "      <td>Criminal Justice and Corrections.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.739258</td>\n",
       "      <td>Debate</td>\n",
       "      <td>16.03</td>\n",
       "      <td>East Asian Languages, Literatures, and Linguis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.738991</td>\n",
       "      <td>Debate</td>\n",
       "      <td>1.11</td>\n",
       "      <td>Plant Sciences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.738960</td>\n",
       "      <td>Debate</td>\n",
       "      <td>16.05</td>\n",
       "      <td>Germanic Languages, Literatures, and Linguistics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.738630</td>\n",
       "      <td>Debate</td>\n",
       "      <td>15.1</td>\n",
       "      <td>Construction Engineering Technology/Technician.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.738137</td>\n",
       "      <td>Debate</td>\n",
       "      <td>26.02</td>\n",
       "      <td>Biochemistry, Biophysics and Molecular Biology.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.736868</td>\n",
       "      <td>Debate</td>\n",
       "      <td>51.23</td>\n",
       "      <td>Rehabilitation and Therapeutic Professions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.735510</td>\n",
       "      <td>Debate</td>\n",
       "      <td>22.02</td>\n",
       "      <td>Legal Research and Advanced Professional Studies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.735133</td>\n",
       "      <td>Debate</td>\n",
       "      <td>29.02</td>\n",
       "      <td>Intelligence, Command Control and Information ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.735118</td>\n",
       "      <td>Debate</td>\n",
       "      <td>38.02</td>\n",
       "      <td>Religion/Religious Studies.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score   query    cip  \\\n",
       "3    1.780989  Debate  50.07   \n",
       "21   1.778566  Debate  38.01   \n",
       "128  1.763501  Debate  14.18   \n",
       "23   1.759955  Debate   45.1   \n",
       "188  1.754979  Debate  52.16   \n",
       "92   1.748719  Debate  19.06   \n",
       "11   1.745737  Debate  45.06   \n",
       "31   1.745663  Debate  14.08   \n",
       "149  1.742177  Debate  52.07   \n",
       "47   1.741174  Debate  31.05   \n",
       "41   1.740697  Debate  43.01   \n",
       "65   1.739258  Debate  16.03   \n",
       "90   1.738991  Debate   1.11   \n",
       "15   1.738960  Debate  16.05   \n",
       "148  1.738630  Debate   15.1   \n",
       "18   1.738137  Debate  26.02   \n",
       "112  1.736868  Debate  51.23   \n",
       "38   1.735510  Debate  22.02   \n",
       "175  1.735133  Debate  29.02   \n",
       "26   1.735118  Debate  38.02   \n",
       "\n",
       "                                              cip_name  \n",
       "3                                Fine and Studio Arts.  \n",
       "21                                         Philosophy.  \n",
       "128                             Materials Engineering.  \n",
       "23                   Political Science and Government.  \n",
       "188                                          Taxation.  \n",
       "92                     Housing and Human Environments.  \n",
       "11                                          Economics.  \n",
       "31                                  Civil Engineering.  \n",
       "149     Entrepreneurial and Small Business Operations.  \n",
       "47   Sports, Kinesiology, and Physical Education/Fi...  \n",
       "41                   Criminal Justice and Corrections.  \n",
       "65   East Asian Languages, Literatures, and Linguis...  \n",
       "90                                     Plant Sciences.  \n",
       "15   Germanic Languages, Literatures, and Linguistics.  \n",
       "148    Construction Engineering Technology/Technician.  \n",
       "18     Biochemistry, Biophysics and Molecular Biology.  \n",
       "112        Rehabilitation and Therapeutic Professions.  \n",
       "38   Legal Research and Advanced Professional Studies.  \n",
       "175  Intelligence, Command Control and Information ...  \n",
       "26                         Religion/Religious Studies.  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = random.choice(all_queries)\n",
    "generate_predictions(query, mse_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
